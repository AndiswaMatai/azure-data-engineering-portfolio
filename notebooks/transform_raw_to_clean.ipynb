# Sample PySpark notebook
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(" ETL").getOrCreate()

# Load mock CSV
df_raw = spark.read.csv("../data/raw/sample_sql_server_table.csv", header=True, inferSchema=True)

# Simple transformation
df_clean = df_raw.dropna().withColumnRenamed("OldColumn", "NewColumn")

# Save cleaned data
df_clean.write.csv("../data/clean/sample_clean_table.csv", header=True)
