# Azure Databricks Streaming from Event Hub to Delta Lake

from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("EventHubStreaming").getOrCreate()

# Mock streaming source (Event Hub placeholder)
stream_df = spark.readStream.format("rate").load()

# Transform stream
transformed_df = stream_df.withColumnRenamed("value", "event_value")

# Write to Delta Lake (Gold layer)
query = (
    transformed_df.writeStream
    .format("delta")
    .outputMode("append")
    .option("checkpointLocation", "/delta/checkpoints/events")
    .start("/delta/gold/events")
)

query.awaitTermination()
